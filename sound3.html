<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      http-equiv="Cache-Control"
      content="no-cache, max-age=0, must-revalidate"
    />
    <title>p5.js faust example</title>
    <link rel="stylesheet" href="styles.css" />
    <script src="https://cdn.jsdelivr.net/npm/p5@1.9.0/lib/p5.js"></script>
    <script src="dsp.js"></script>
  </head>

  <body class="grid-container fullbody">
    <nav class="primary-nav">
      <li><a href="index.html">Interaction 1</a></li>
      <li><a href="sound2.html">Interaction 2</a></li>
      <li><a href="sound3.html">Interaction 3</a></li>
    </nav>

    <div id="info">
      <p>
        <b>Interaction 3: Strike Motion → Marimba</b>
        <br />
        <br />
        <b>Gesture:</b> スティックをたたくような動き (The phone is used to make a striking motion like hitting with a stick)
        <br />
        <b>Sound:</b> Marimba (synthesized using Faust)
        <br />
        <br />
        <b>Design Motivation:</b>
        <br />
        This mapping connects the striking motion of the device with the sound of a marimba. When you make a sudden, sharp movement with the device (like striking with a stick), the acceleration sensors detect the rapid change in motion and trigger the marimba sound. Each strike produces a different pitch, creating a percussive and musical interaction.
        <br />
        <br />
        This interaction design is motivated by the physical analogy between striking a marimba with mallets and making a striking motion with the device. Just as a marimba player strikes the bars with mallets to produce sound, the user strikes the air (or a surface) with the device to trigger marimba notes. The use case scenario could be a virtual marimba app, a music education tool, or an interactive percussion instrument where users can play marimba sounds through natural striking gestures, making music through physical movement.
      </p>
    </div>

    <footer>
      <p>
        Developed by Maurizio Berta and Laura McHugh
        <br />
        for
        <a href="https://github.com/mauriziobrt/DT2140-Sound-Interaction-Lab"
          >DT2140 Multimodal Interfaces Sound Interaction Lab</a
        >
        <br />
        KTH Royal Institute of Technology, 2025
      </p>
    </footer>
  </body>
  <script src="helpers.js"></script>
  <script src="interaction-3.js"></script>
  <script src="sketch.js"></script>
</html>
