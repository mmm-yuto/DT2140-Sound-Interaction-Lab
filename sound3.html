<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      http-equiv="Cache-Control"
      content="no-cache, max-age=0, must-revalidate"
    />
    <title>p5.js faust example</title>
    <link rel="stylesheet" href="styles.css" />
    <script src="https://cdn.jsdelivr.net/npm/p5@1.9.0/lib/p5.js"></script>
    <script src="dsp.js"></script>
  </head>

  <body class="grid-container fullbody">
    <nav class="primary-nav">
      <li><a href="index.html">Interaction 1</a></li>
      <li><a href="sound2.html">Interaction 2</a></li>
      <li><a href="sound3.html">Interaction 3</a></li>
    </nav>

    <div id="info">
      <p>
        <b>Interaction 3: Tilt Side to Side â†’ Brass</b>
        <br />
        <br />
        <b>Gesture:</b> The phone is placed flat and tilted from side to side
        <br />
        <b>Sound:</b> Brass instrument (synthesized using Faust)
        <br />
        <br />
        <b>Design Motivation:</b>
        <br />
        This mapping connects the side-to-side tilting motion of the device with the breath pressure control of a brass instrument. As you tilt the device left or right, the rotation angle (rotationX/Roll) is mapped to the pressure parameter of the brass sound synthesis, creating a continuous and expressive control mechanism. The more you tilt, the higher the pressure, which affects the intensity and character of the brass sound.
        <br />
        <br />
        This interaction design is motivated by the physical analogy between breath control in brass instruments and the tilting gesture. Just as a brass player controls the sound by varying breath pressure, the user controls the sound by varying the tilt angle of the device. The use case scenario could be a virtual brass instrument app, a music education tool, or an expressive musical interface where users can perform brass sounds through intuitive physical gestures.
      </p>
    </div>

    <footer>
      <p>
        Developed by Maurizio Berta and Laura McHugh
        <br />
        for
        <a href="https://github.com/mauriziobrt/DT2140-Sound-Interaction-Lab"
          >DT2140 Multimodal Interfaces Sound Interaction Lab</a
        >
        <br />
        KTH Royal Institute of Technology, 2025
      </p>
    </footer>
  </body>
  <script src="helpers.js"></script>
  <script src="interaction-3.js"></script>
  <script src="sketch.js"></script>
</html>
