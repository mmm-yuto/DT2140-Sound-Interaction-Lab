<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      http-equiv="Cache-Control"
      content="no-cache, max-age=0, must-revalidate"
    />
    <title>p5.js faust example</title>
    <link rel="stylesheet" href="styles.css" /> 
    <script src="https://cdn.jsdelivr.net/npm/p5@1.9.0/lib/p5.js"></script>
    <script src="dsp.js"></script>
  </head>

  <body class="grid-container fullbody">
    <nav class="primary-nav">
      <li><a href="index.html">Interaction 1</a></li>
      <li><a href="sound2.html">Interaction 2</a></li>
      <li><a href="sound3.html">Interaction 3</a></li>
    </nav>

    <div id="info">
      <p>
        <b>Interaction 1: Tilt → Engine</b>
        <br />
        <br />
        <b>Gesture:</b> Tilt the device along the X-axis (Roll angle). The engine sound is triggered when the tilt angle (rotationX) exceeds 90°.
        <br />
        <b>Sound:</b> Engine (synthesized using Faust)
        <br />
        <br />
        <b>How it works:</b>
        <br />
        • When the device is tilted and rotationX exceeds 90° (in either direction), the engine sound is triggered
        <br />
        • Each trigger produces a short engine sound (100ms)
        <br />
        • A cooldown period (200ms) prevents continuous triggering
        <br />
        <br />
        <b>Design Motivation:</b>
        <br />
        This mapping connects the device's tilt angle (rotationX) with the engine sound through a discrete trigger system. When the user tilts the device beyond 90°, it triggers an engine sound, creating an intuitive mapping between physical orientation and sound output. This design is motivated by the need for clear, predictable feedback in applications such as vehicle simulators, racing games, or interactive sound installations where users need to understand the relationship between their physical gesture and the resulting sound output.
      </p>
    </div>

    <footer>
      <p>
        Developed by Maurizio Berta and Laura McHugh
        <br />
        for
        <a href="https://github.com/mauriziobrt/DT2140-Sound-Interaction-Lab"
          >DT2140 Multimodal Interfaces Sound Interaction Lab</a
        >
        <br />
        KTH Royal Institute of Technology, 2025
      </p>
    </footer>
  </body>
  <script src="helpers.js"></script>
  <script src="interaction-1.js"></script>
  <script src="sketch.js"></script>
</html>
